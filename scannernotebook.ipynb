{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "# def get_sp500_tickers():\n",
    "#     url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#     table = soup.find('table', {'id': 'constituents'})\n",
    "#     tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "#     return tickers\n",
    "\n",
    "# # Get the S&P 500 tickers\n",
    "# sp500_tickers = get_sp500_tickers()\n",
    "\n",
    "# # Save the tickers to a CSV file\n",
    "# pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('sp500_tickers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers# Get only the first 10 tickers\n",
    "\n",
    "# Get the S&P 500 tickers\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "\n",
    "# Display the tickers\n",
    "print(\"S&P 500 Tickers:\")\n",
    "print(sp500_tickers)\n",
    "\n",
    "# Save the tickers to a CSV file\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('sp500_tickers.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the timeframes and their corresponding date ranges\n",
    "\n",
    "# Read the tickers from the CSV file\n",
    "tickers_df = pd.read_csv('sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "timeframes = {\n",
    "    # '15m': timedelta(days=60),\n",
    "    # '1h': timedelta(days=730),\n",
    "    '1d': timedelta(days=180),\n",
    "    # '1wk': timedelta(days=3*365)\n",
    "}\n",
    "\n",
    "# Define the recent period (in days)\n",
    "recent_period = 1\n",
    "\n",
    "# Function to download data for a given ticker and timeframe\n",
    "def download_data(ticker, timeframe, start_date, end_date):\n",
    "    return yf.download(ticker, start=start_date, end=end_date, interval=timeframe)\n",
    "\n",
    "# Dictionary to store data for each timeframe\n",
    "data = {tf: {} for tf in timeframes}\n",
    "\n",
    "# Download data for each ticker and timeframe\n",
    "end_date = datetime.now()\n",
    "for ticker in tickers:\n",
    "    for tf, delta in timeframes.items():\n",
    "        start_date = end_date - delta\n",
    "        try:\n",
    "            data[tf][ticker] = download_data(ticker, tf, start_date, end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data for {ticker} with timeframe {tf}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List to store screener results\n",
    "screener_results = []\n",
    "\n",
    "# Applying the custom indicator and generating buy/sell signals\n",
    "for tf in timeframes:\n",
    "    for ticker in data[tf]:\n",
    "        df = data[tf][ticker]\n",
    "        \n",
    "        # Round OHLC values to two decimal points\n",
    "        df['Open'] = df['Open'].round(2)\n",
    "        df['High'] = df['High'].round(2)\n",
    "        df['Low'] = df['Low'].round(2)\n",
    "        df['Close'] = df['Close'].round(2)\n",
    "        \n",
    "       # --- Existing calculations ---\n",
    "        # Linear Regression Curves\n",
    "        df['reg1'] = ta.linreg(df['Close'], length=10)\n",
    "        df['reg2'] = ta.linreg(df['Close'], length=14)\n",
    "        df['reg3'] = ta.linreg(df['Close'], length=30)\n",
    "\n",
    "        # R-squared Calculation\n",
    "        r2_length = 14\n",
    "        df['r2_raw'] = df['Close'].rolling(window=r2_length).apply(\n",
    "            lambda x: np.corrcoef(x, np.arange(r2_length))[0, 1]**2\n",
    "        )\n",
    "        df['r2'] = df['r2_raw'] * 100  # Normalized to [0, 100]\n",
    "        df['r2_smoothed'] = df['r2'].rolling(window=3).mean()\n",
    "\n",
    "        # --- Flatten the columns if they are a MultiIndex ---\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            # This will take the first level of the MultiIndex as the new columns.\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "        # --- RSI Calculation using the DataFrame accessor ---\n",
    "        # Explicitly specify the 'Close' column.\n",
    "        df.ta.rsi(close='Close', length=14, append=True)\n",
    "        # This will add a new column named 'RSI_14' to df.\n",
    "\n",
    "        # --- Buy and Sell Signals ---\n",
    "        df['buy_signal'] = np.where((df['r2_smoothed'] > 90) & (df['RSI_14'] < 30), 1, 0)\n",
    "        df['sell_signal'] = np.where((df['r2_smoothed'] > 90) & (df['RSI_14'] > 70), 1, 0)\n",
    "\n",
    "\n",
    "                \n",
    "                # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f'{ticker}_{tf}_data.csv')\n",
    "        \n",
    "        \n",
    "        # Filter for recent periods\n",
    "        recent_date_cutoff = df.index.max() - pd.Timedelta(days=recent_period)\n",
    "        df = df[df.index >= recent_date_cutoff]\n",
    "        \n",
    "        # Filter rows with buy or sell signals\n",
    "        df_filtered = df[(df['buy_signal'] == 1) | (df['sell_signal'] == 1)]\n",
    "        \n",
    "        # Append results to screener list\n",
    "        if not df_filtered.empty:\n",
    "            for index, row in df_filtered.iterrows():\n",
    "                screener_results.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Date': index,\n",
    "                    'Buy Signal': row['buy_signal'],\n",
    "                    'Sell Signal': row['sell_signal']\n",
    "                })\n",
    "\n",
    "# Save screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "# screener_df.to_csv('screener_results.csv', index=False)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Screener results:\")\n",
    "print(screener_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regession line crossed ta alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the tickers from the CSV file\n",
    "tickers_df = pd.read_csv('sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Define the timeframes and their corresponding date ranges\n",
    "timeframes = {\n",
    "    # '15m': timedelta(days=60),\n",
    "    '1h': timedelta(days=30),\n",
    "    # '1d': timedelta(days=3*365),\n",
    "    # '1wk': timedelta(days=3*365)\n",
    "}\n",
    "\n",
    "# Define the recent period (in days)\n",
    "recent_period = 1\n",
    "\n",
    "# Function to download data for a given ticker and timeframe\n",
    "def download_data(ticker, timeframe, start_date, end_date):\n",
    "    return yf.download(ticker, start=start_date, end=end_date, interval=timeframe)\n",
    "\n",
    "# Dictionary to store data for each timeframe\n",
    "data = {tf: {} for tf in timeframes}\n",
    "\n",
    "# Download data for each ticker and timeframe\n",
    "end_date = datetime.now()\n",
    "for ticker in tickers:\n",
    "    for tf, delta in timeframes.items():\n",
    "        start_date = end_date - delta\n",
    "        try:\n",
    "            data[tf][ticker] = download_data(ticker, tf, start_date, end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data for {ticker} with timeframe {tf}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List to store screener results\n",
    "screener_results = []\n",
    "\n",
    "# Applying the custom indicator and generating buy/sell signals\n",
    "for tf in timeframes:\n",
    "    for ticker in data[tf]:\n",
    "        df = data[tf][ticker]\n",
    "        \n",
    "                # If the DataFrame columns are a MultiIndex, flatten them\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "        \n",
    "        # Round OHLC values to two decimal points\n",
    "        df['Open'] = df['Open'].round(2)\n",
    "        df['High'] = df['High'].round(2)\n",
    "        df['Low'] = df['Low'].round(2)\n",
    "        df['Close'] = df['Close'].round(2)\n",
    "        \n",
    "       # --- Existing calculations ---\n",
    "        # Linear Regression Curves\n",
    "        \n",
    "        df['reg1'] = ta.linreg(df['Close'], length=25)\n",
    "        df['reg2'] = ta.linreg(df['Close'], length=50)\n",
    "        \n",
    "        \n",
    "        # df['reg3'] = ta.linreg(df['Close'], length=30)\n",
    "\n",
    "        # R-squared Calculation\n",
    "        # r2_length = 14\n",
    "        # df['r2_raw'] = df['Close'].rolling(window=r2_length).apply(\n",
    "        #     lambda x: np.corrcoef(x, np.arange(r2_length))[0, 1]**2\n",
    "        # )\n",
    "        # df['r2'] = df['r2_raw'] * 100  # Normalized to [0, 100]\n",
    "        # df['r2_smoothed'] = df['r2'].rolling(window=3).mean()\n",
    "\n",
    "        # --- Flatten the columns if they are a MultiIndex ---\n",
    "        # if isinstance(df.columns, pd.MultiIndex):\n",
    "        #     # This will take the first level of the MultiIndex as the new columns.\n",
    "        #     df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "        # --- RSI Calculation using the DataFrame accessor ---\n",
    "        # Explicitly specify the 'Close' column.\n",
    "        # df.ta.rsi(close='Close', length=14, append=True)\n",
    "        # This will add a new column named 'RSI_14' to df.\n",
    "\n",
    "        # --- Buy and Sell Signals ---\n",
    "        # df['buy_signal'] = np.where((df['r2_smoothed'] > 90) & (df['RSI_14'] < 30), 1, 0)\n",
    "        # df['sell_signal'] = np.where((df['r2_smoothed'] > 90) & (df['RSI_14'] > 70), 1, 0)\n",
    "\n",
    "        df['buy_signal'] = np.where(\n",
    "            (df['reg1'] > df['reg2']) & (df['reg1'].shift(1) <= df['reg2'].shift(1)),\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Sell Signal: When the 25-period line (reg1) crosses below the 50-period line (reg2)\n",
    "        df['sell_signal'] = np.where(\n",
    "            (df['reg1'] < df['reg2']) & (df['reg1'].shift(1) >= df['reg2'].shift(1)),\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "                \n",
    "                # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f'{ticker}_{tf}_data.csv')\n",
    "        \n",
    "        \n",
    "        # Filter for recent periods\n",
    "        recent_date_cutoff = df.index.max() - pd.Timedelta(days=recent_period)\n",
    "        df = df[df.index >= recent_date_cutoff]\n",
    "        \n",
    "        # Filter rows with buy or sell signals\n",
    "        df_filtered = df[(df['buy_signal'] == 1) | (df['sell_signal'] == 1)]\n",
    "        \n",
    "        # Append results to screener list\n",
    "        if not df_filtered.empty:\n",
    "            for index, row in df_filtered.iterrows():\n",
    "                screener_results.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Date': index,\n",
    "                    'Buy Signal': row['buy_signal'],\n",
    "                    'Sell Signal': row['sell_signal']\n",
    "                })\n",
    "\n",
    "# Save screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "# screener_df.to_csv('screener_results.csv', index=False)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Screener results:\")\n",
    "print(screener_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test previous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers\n",
    "\n",
    "# Function to send message to Telegram\n",
    "def send_telegram_message(message):\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "    # Get the S&P 500 tickers\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "\n",
    "# Ensure the stockdata directory exists\n",
    "os.makedirs('stockdata', exist_ok=True)\n",
    "\n",
    "# Save the tickers to a CSV file in the stockdata folder\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "\n",
    "# Read the tickers from the CSV file in the stockdata folder\n",
    "tickers_df = pd.read_csv('stockdata/sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Define the timeframes and their corresponding date ranges\n",
    "timeframes = {\n",
    "    # '15m': timedelta(days=60),\n",
    "    '1h': timedelta(days=30),\n",
    "    # '1d': timedelta(days=90),\n",
    "    # '1wk': timedelta(days=3*365)\n",
    "}\n",
    "\n",
    "# Define the recent period (in days)\n",
    "recent_period = 1\n",
    "\n",
    "# Function to download data for a given ticker and timeframe\n",
    "def download_data(ticker, timeframe, start_date, end_date):\n",
    "    return yf.download(ticker, start=start_date, end=end_date, interval=timeframe)\n",
    "\n",
    "# Dictionary to store data for each timeframe\n",
    "data = {tf: {} for tf in timeframes}\n",
    "\n",
    "# Download historical data for each ticker and timeframe\n",
    "end_date = datetime.now()\n",
    "for ticker in tickers:\n",
    "    for tf, delta in timeframes.items():\n",
    "        start_date = end_date - delta\n",
    "        try:\n",
    "            df = download_data(ticker, tf, start_date, end_date)\n",
    "            if df.empty:\n",
    "                print(f\"No data available for {ticker} on timeframe {tf}. Skipping.\")\n",
    "                continue\n",
    "            data[tf][ticker] = df\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download data for {ticker} with timeframe {tf}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# List to store screener results\n",
    "screener_results = []\n",
    "\n",
    "# Applying the custom indicator and generating buy/sell signals\n",
    "for tf in timeframes:\n",
    "    for ticker in data[tf]:\n",
    "        df = data[tf][ticker]\n",
    "        \n",
    "                # If the DataFrame columns are a MultiIndex, flatten them\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "        \n",
    "        # Round OHLC values to two decimal points\n",
    "        df['Open'] = df['Open'].round(2)\n",
    "        df['High'] = df['High'].round(2)\n",
    "        df['Low'] = df['Low'].round(2)\n",
    "        df['Close'] = df['Close'].round(2)\n",
    "        \n",
    "    # --- Existing calculations ---\n",
    "        # Linear Regression Curves\n",
    "        \n",
    "        df['reg1'] = ta.linreg(df['Close'], length=25)\n",
    "        df['reg2'] = ta.linreg(df['Close'], length=50)\n",
    "        \n",
    "\n",
    "        df['buy_signal'] = np.where(\n",
    "            (df['reg1'] > df['reg2']) & (df['reg1'].shift(1) <= df['reg2'].shift(1)),\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Sell Signal: When the 25-period line (reg1) crosses below the 50-period line (reg2)\n",
    "        df['sell_signal'] = np.where(\n",
    "            (df['reg1'] < df['reg2']) & (df['reg1'].shift(1) >= df['reg2'].shift(1)),\n",
    "            1,\n",
    "            0\n",
    "        )\n",
    "                \n",
    "        # Save each ticker's data to a CSV file in the stockdata folder\n",
    "        df.to_csv(f'stockdata/{ticker}_{tf}_data.csv')\n",
    "\n",
    "        \n",
    "        hoursback =1 \n",
    "        # Filter for recent periods\n",
    "        recent_date_cutoff = df.index.max() - pd.Timedelta(hours=hoursback)\n",
    "        df = df[df.index >= recent_date_cutoff]\n",
    "        \n",
    "        # Filter rows with buy or sell signals\n",
    "        df_filtered = df[(df['buy_signal'] == 1) | (df['sell_signal'] == 1)]\n",
    "        \n",
    "        # Append results to screener list\n",
    "        if not df_filtered.empty:\n",
    "            for index, row in df_filtered.iterrows():\n",
    "                screener_results.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Date': index,\n",
    "                    'Buy Signal': row['buy_signal'],\n",
    "                    'Sell Signal': row['sell_signal']\n",
    "                })\n",
    "\n",
    "# Save screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "screener_df.to_csv('Regression_cross_screener_results_1h.csv', index=False)\n",
    "\n",
    "\n",
    "# Send results to Telegram\n",
    "if not screener_df.empty:\n",
    "    message = \"Hourly screener Results:\\n Buy=linreg 25 crossover linreg 50 \\n Sell=linreg 25 cross below linreg 50 \\n\" + screener_df.to_string(index=False)\n",
    "    send_telegram_message(message)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Hourly screener Results:\\n Buy=linreg 25 crossover linreg 50 \\n Sell=linreg 25 cross below linreg 50 \\n\")\n",
    "print(screener_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp500_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession('yfinance.cache')\n",
    "session.headers['User-agent'] = 'my-program/1.0'\n",
    "ticker = yf.Ticker('AAPL', session=session)\n",
    "\n",
    "# The scraped response will be stored in the cache\n",
    "ticker.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "   pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "   limiter=Limiter(RequestRate(2, Duration.SECOND*5)),  # max 2 requests per 5 seconds\n",
    "   bucket_class=MemoryQueueBucket,\n",
    "   backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "   pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "   limiter=Limiter(RequestRate(2, Duration.SECOND*5)),  # max 2 requests per 5 seconds\n",
    "   bucket_class=MemoryQueueBucket,\n",
    "   backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "dat = yf.Tickers(sp500_tickers,session=session) \n",
    "\n",
    "# get historical market data\n",
    "his_data = dat.history(period='1mo', interval='60m')\n",
    "# Print the columns of the downloaded historical data\n",
    "print(his_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "\n",
    "# Function to check if the US market is open\n",
    "def is_us_market_open():\n",
    "    \"\"\"Checks if the current time is within US market hours (9:30 AM - 4:00 PM ET) and not on weekends.\"\"\"\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    now = datetime.now(eastern)\n",
    "    if now.weekday() in [5, 6]:  # Saturday and Sunday\n",
    "        return False\n",
    "    market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "    market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "    return market_open <= now <= market_close\n",
    "\n",
    "# if not is_us_market_open():\n",
    "#     print(\"The US market is currently closed. Script execution halted.\")\n",
    "# else:\n",
    "load_dotenv()\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers\n",
    "\n",
    "# Function to send a message via Telegram\n",
    "def send_telegram_message(message):\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "# Retrieve the S&P 500 tickers and save them to a CSV file\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "os.makedirs('stockdata', exist_ok=True)\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "\n",
    "# Read tickers from CSV\n",
    "tickers_df = pd.read_csv('stockdata/sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# --- New Bulk Download Approach Using a Cached & Rate-Limited Session ---\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "    limiter=Limiter(RequestRate(2, Duration.SECOND * 5)),  # max 2 requests per 5 seconds\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "\n",
    "# Create a Tickers object with the custom session.\n",
    "# yf.Tickers accepts a space-separated string of tickers.\n",
    "tickers_str = \" \".join(tickers)\n",
    "dat = yf.Tickers(tickers_str, session=session)\n",
    "\n",
    "# Download historical data for all tickers (1 month period, 1-day interval)\n",
    "try:\n",
    "    his_data = dat.history(period='1mo', interval='1d')\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading bulk data: {e}\")\n",
    "    his_data = None\n",
    "\n",
    "screener_results = []\n",
    "\n",
    "if his_data is not None:\n",
    "    # Process data for each ticker individually\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Extract the ticker-specific data from the MultiIndex DataFrame\n",
    "            df = his_data.xs(ticker, axis=1, level='Ticker')\n",
    "            # Flatten the columns to a single level (Price types)\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "            \n",
    "            # Round OHLC values to two decimals if available\n",
    "            for col in ['Open', 'High', 'Low', 'Close']:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].round(2)\n",
    "\n",
    "            # Calculate linear regression curves using a 25- and 50-day lookback\n",
    "            df['reg1'] = ta.linreg(df['Close'], length=25)\n",
    "            df['reg2'] = ta.linreg(df['Close'], length=50)\n",
    "\n",
    "            # Generate buy and sell signals\n",
    "            df['buy_signal'] = np.where((df['reg1'] > df['reg2']) & (df['reg1'].shift(1) <= df['reg2'].shift(1)), 1, 0)\n",
    "            df['sell_signal'] = np.where((df['reg1'] < df['reg2']) & (df['reg1'].shift(1) >= df['reg2'].shift(1)), 1, 0)\n",
    "\n",
    "            # Save each ticker's data to a CSV file\n",
    "            csv_filename = f'stockdata/{ticker}_1d_data.csv'\n",
    "            df.to_csv(csv_filename)\n",
    "\n",
    "            # Filter for recent data (last day)\n",
    "            if not df.empty:\n",
    "                recent_date_cutoff = df.index.max() - pd.Timedelta(days=1)\n",
    "                df_recent = df[df.index >= recent_date_cutoff]\n",
    "                df_filtered = df_recent[(df_recent['buy_signal'] == 1) | (df_recent['sell_signal'] == 1)]\n",
    "                if not df_filtered.empty:\n",
    "                    for index, row in df_filtered.iterrows():\n",
    "                        screener_results.append({\n",
    "                            'Ticker': ticker,\n",
    "                            'Date': index,\n",
    "                            'Buy Signal': row['buy_signal'],\n",
    "                            'Sell Signal': row['sell_signal']\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process data for ticker {ticker}: {e}\")\n",
    "\n",
    "# Save the screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "screener_df.to_csv('Regression_cross_screener_results_1d.csv', index=False)\n",
    "\n",
    "# Send the results via Telegram if there are any signals\n",
    "if not screener_df.empty:\n",
    "    message = (\n",
    "        \"Daily Screener Results:\\n\"\n",
    "        \"Buy = linreg 25 crossover linreg 50\\n\"\n",
    "        \"Sell = linreg 25 cross below linreg 50\\n\"\n",
    "        f\"{screener_df.to_string(index=False)}\"\n",
    "    )\n",
    "    # send_telegram_message(message)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Daily Screener Results:\\nBuy = linreg 25 crossover linreg 50\\nSell = linreg 25 cross below linreg 50\\n\")\n",
    "print(screener_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Retrieved %d tickers, sample: %s\", len(sp500_tickers), sp500_tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time sp500_tickers = get_sp500_tickers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "try:\n",
    "    his_data = dat.history(period='1mo', interval='1d')\n",
    "    print(\"Historical data shape:\", his_data.shape)\n",
    "except Exception as e:\n",
    "    print(\"Error downloading bulk data:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "\n",
    "# Check if US market is open\n",
    "def is_us_market_open():\n",
    "    \"\"\"Checks if the current time is within US market hours (9:30 AM - 4:00 PM ET) and not on weekends.\"\"\"\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    now = datetime.now(eastern)\n",
    "    if now.weekday() in [5, 6]:  # Saturday and Sunday\n",
    "        return False\n",
    "    market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "    market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "    return market_open <= now <= market_close\n",
    "\n",
    "# if not is_us_market_open():\n",
    "#     print(\"The US market is currently closed. Script execution halted.\")\n",
    "# else:\n",
    "load_dotenv()\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers\n",
    "\n",
    "# Function to send message to Telegram\n",
    "def send_telegram_message(message):\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "# Get the S&P 500 tickers and save to CSV\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "os.makedirs('stockdata', exist_ok=True)\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "\n",
    "# Read tickers from CSV\n",
    "tickers_df = pd.read_csv('stockdata/sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Define the timeframes (here using only daily data for 90 days)\n",
    "timeframes = {\n",
    "    '1d': timedelta(days=90),\n",
    "    # Additional intervals (e.g., '15m', '1h', '1wk') can be added as needed\n",
    "}\n",
    "recent_period = 1  # in days\n",
    "\n",
    "# --- New download approach using CachedLimiterSession and yf.Tickers ---\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "    limiter=Limiter(RequestRate(2, Duration.SECOND * 5)),  # max 2 requests per 5 seconds\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "\n",
    "# Create a Tickers object using all tickers with the custom session.\n",
    "# Note: yf.Tickers accepts a string of tickers separated by spaces.\n",
    "tickers_str = \" \".join(tickers)\n",
    "dat = yf.Tickers(tickers_str, session=session)\n",
    "\n",
    "# Dictionary to hold downloaded data for each timeframe\n",
    "data = {}\n",
    "screener_results = []  # list to store screener signal results\n",
    "\n",
    "# Loop over timeframes and download bulk historical data\n",
    "for tf, delta in timeframes.items():\n",
    "    # Use period string based on the desired date range, e.g. \"90d\" for 90 days\n",
    "    period_str = f\"{delta.days}d\"\n",
    "    try:\n",
    "        his_data = dat.history(period=period_str, interval=tf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading bulk data for interval {tf}: {e}\")\n",
    "        continue\n",
    "\n",
    "    data[tf] = {}\n",
    "    # his_data has a MultiIndex for columns: (Price, Ticker)\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            # Extract data for a single ticker from the MultiIndex DataFrame\n",
    "            df = his_data.xs(ticker, axis=1, level='Ticker')\n",
    "            # Flatten the columns (Price types) if needed\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "            # Round OHLC values to two decimals\n",
    "            for col in ['Open', 'High', 'Low', 'Close']:\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].round(2)\n",
    "\n",
    "            # Calculate linear regression curves using pandas_ta\n",
    "            df['reg1'] = ta.linreg(df['Close'], length=25)\n",
    "            df['reg2'] = ta.linreg(df['Close'], length=50)\n",
    "\n",
    "            # Generate buy and sell signals\n",
    "            df['buy_signal'] = np.where((df['reg1'] > df['reg2']) & (df['reg1'].shift(1) <= df['reg2'].shift(1)), 1, 0)\n",
    "            df['sell_signal'] = np.where((df['reg1'] < df['reg2']) & (df['reg1'].shift(1) >= df['reg2'].shift(1)), 1, 0)\n",
    "\n",
    "            # Save each ticker's data to CSV\n",
    "            csv_filename = f'stockdata/{ticker}_{tf}_data.csv'\n",
    "            df.to_csv(csv_filename)\n",
    "\n",
    "            # Filter for the recent period\n",
    "            if not df.empty:\n",
    "                recent_date_cutoff = df.index.max() - pd.Timedelta(days=recent_period)\n",
    "                df_recent = df[df.index >= recent_date_cutoff]\n",
    "                df_filtered = df_recent[(df_recent['buy_signal'] == 1) | (df_recent['sell_signal'] == 1)]\n",
    "                if not df_filtered.empty:\n",
    "                    for index, row in df_filtered.iterrows():\n",
    "                        screener_results.append({\n",
    "                            'Ticker': ticker,\n",
    "                            'Date': index,\n",
    "                            'Buy Signal': row['buy_signal'],\n",
    "                            'Sell Signal': row['sell_signal']\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process data for ticker {ticker} on timeframe {tf}: {e}\")\n",
    "\n",
    "# Save screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "screener_df.to_csv('Regression_cross_screener_results_1d.csv', index=False)\n",
    "\n",
    "# Send results to Telegram if available\n",
    "if not screener_df.empty:\n",
    "    message = (\n",
    "        \"Daily screener Results:\\n\"\n",
    "        \"Buy = linreg 25 crossover linreg 50\\n\"\n",
    "        \"Sell = linreg 25 cross below linreg 50\\n\"\n",
    "        f\"{screener_df.to_string(index=False)}\"\n",
    "    )\n",
    "    # send_telegram_message(message)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Daily screener Results:\\nBuy = linreg 25 crossover linreg 50\\nSell = linreg 25 cross below linreg 50\\n\")\n",
    "print(screener_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix version 1d screener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "\n",
    "# Check if US market is open\n",
    "def is_us_market_open():\n",
    "    \"\"\"Checks if the current time is within US market hours (9:30 AM - 4:00 PM ET) and not on weekends.\"\"\"\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    now = datetime.now(eastern)\n",
    "    if now.weekday() in [5, 6]:  # Saturday and Sunday\n",
    "        return False\n",
    "    market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "    market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "    return market_open <= now <= market_close\n",
    "\n",
    "# For debugging in Jupyter, you can disable the market check.\n",
    "# if not is_us_market_open():\n",
    "#     print(\"The US market is currently closed. Script execution halted.\")\n",
    "# else:\n",
    "load_dotenv()\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers\n",
    "\n",
    "# Function to send a message via Telegram\n",
    "def send_telegram_message(message):\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "# Get the S&P 500 tickers and save to CSV\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "os.makedirs('stockdata', exist_ok=True)\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "\n",
    "# Read tickers from CSV\n",
    "tickers_df = pd.read_csv('stockdata/sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Define the timeframes (here using only daily data for 90 days)\n",
    "timeframes = {\n",
    "    '1d': timedelta(days=90),\n",
    "}\n",
    "recent_period = 1  # in days\n",
    "\n",
    "# --- New download approach using CachedLimiterSession and yf.Tickers ---\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "    limiter=Limiter(RequestRate(2, Duration.SECOND * 5)),  # max 2 requests per 5 seconds\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "\n",
    "# Create a Tickers object using all tickers with the custom session.\n",
    "# Note: yf.Tickers accepts a string of tickers separated by spaces.\n",
    "tickers_str = \" \".join(tickers)\n",
    "dat = yf.Tickers(tickers_str, session=session)\n",
    "\n",
    "data = {}\n",
    "screener_results = []  # list to store screener signal results\n",
    "\n",
    "for tf, delta in timeframes.items():\n",
    "    # Use period string based on the desired date range, e.g. \"90d\" for 90 days\n",
    "    period_str = f\"{delta.days}d\"\n",
    "    try:\n",
    "        his_data = dat.history(period=period_str, interval=tf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading bulk data for interval {tf}: {e}\")\n",
    "        continue\n",
    "\n",
    "    data[tf] = {}\n",
    "    # Get available tickers in the downloaded data from the MultiIndex level 'Ticker'\n",
    "    available_tickers = set(his_data.columns.get_level_values('Ticker'))\n",
    "    for ticker in tickers:\n",
    "        if ticker not in available_tickers:\n",
    "            print(f\"Ticker {ticker} not found in historical data, skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            # Extract data for a single ticker from the MultiIndex DataFrame and make a copy\n",
    "            df = his_data.xs(ticker, axis=1, level='Ticker').copy()\n",
    "            # Flatten the columns (Price types) if needed\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "            # Round OHLC values to two decimals using .loc to avoid SettingWithCopyWarning\n",
    "            for col in ['Open', 'High', 'Low', 'Close']:\n",
    "                if col in df.columns:\n",
    "                    df.loc[:, col] = df[col].round(2)\n",
    "\n",
    "            # Calculate linear regression curves using pandas_ta\n",
    "            df['reg1'] = ta.linreg(df['Close'], length=25)\n",
    "            df['reg2'] = ta.linreg(df['Close'], length=50)\n",
    "\n",
    "            # Generate buy and sell signals\n",
    "            df['buy_signal'] = np.where((df['reg1'] > df['reg2']) & (df['reg1'].shift(1) <= df['reg2'].shift(1)), 1, 0)\n",
    "            df['sell_signal'] = np.where((df['reg1'] < df['reg2']) & (df['reg1'].shift(1) >= df['reg2'].shift(1)), 1, 0)\n",
    "\n",
    "            # Save each ticker's data to a CSV file\n",
    "            csv_filename = f'stockdata/{ticker}_{tf}_data.csv'\n",
    "            df.to_csv(csv_filename)\n",
    "\n",
    "            # Filter for the recent period\n",
    "            if not df.empty:\n",
    "                recent_date_cutoff = df.index.max() - pd.Timedelta(days=recent_period)\n",
    "                df_recent = df[df.index >= recent_date_cutoff]\n",
    "                df_filtered = df_recent[(df_recent['buy_signal'] == 1) | (df_recent['sell_signal'] == 1)]\n",
    "                if not df_filtered.empty:\n",
    "                    for index, row in df_filtered.iterrows():\n",
    "                        screener_results.append({\n",
    "                            'Ticker': ticker,\n",
    "                            'Date': index,\n",
    "                            'Buy Signal': row['buy_signal'],\n",
    "                            'Sell Signal': row['sell_signal']\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process data for ticker {ticker} on timeframe {tf}: {e}\")\n",
    "\n",
    "# Save the screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "screener_df.to_csv('Regression_cross_screener_results_1d.csv', index=False)\n",
    "\n",
    "# Optionally, send results to Telegram if available\n",
    "if not screener_df.empty:\n",
    "    message = (\n",
    "        \"Daily Screener Results:\\n\"\n",
    "        \"Buy = linreg 25 crossover linreg 50\\n\"\n",
    "        \"Sell = linreg 25 cross below linreg 50\\n\"\n",
    "        f\"{screener_df.to_string(index=False)}\"\n",
    "    )\n",
    "    # Uncomment the following line to send the message:\n",
    "    send_telegram_message(message)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"Daily Screener Results:\\nBuy = linreg 25 crossover linreg 50\\nSell = linreg 25 cross below linreg 50\\n\")\n",
    "print(screener_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[**********************58%***                    ]  292 of 503 completedUnable to deserialize response: a bytes-like object is required, not 'NoneType'\n",
      "[*********************100%***********************]  502 of 503 completed\n",
      "\n",
      "3 Failed downloads:\n",
      "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (period=30d)')\n",
      "['TFX']: EOFError('Ran out of input')\n",
      "['BRK.B']: YFPricesMissingError('possibly delisted; no price data found  (period=30d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2hr Screener Results:\n",
      "Buy = linreg 25 crossover linreg 50\n",
      "Sell = linreg 25 cross below linreg 50\n",
      "\n",
      "   Ticker                      Date  Buy Signal  Sell Signal\n",
      "53   TRMB 2025-02-21 20:00:00+00:00         0.0          1.0\n",
      "54    WFC 2025-02-21 18:00:00+00:00         0.0          1.0\n",
      "55    WST 2025-02-21 18:00:00+00:00         1.0          0.0\n",
      "56    WDC 2025-02-21 18:00:00+00:00         0.0          1.0\n",
      "57    ZTS 2025-02-21 20:00:00+00:00         1.0          0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import yfinance as yf\n",
    "\n",
    "# Check if US market is open\n",
    "def is_us_market_open():\n",
    "    \"\"\"Checks if the current time is within US market hours (9:30 AM - 4:00 PM ET) and not on weekends.\"\"\"\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    now = datetime.now(eastern)\n",
    "    if now.weekday() in [5, 6]:  # Saturday and Sunday\n",
    "        return False\n",
    "    market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "    market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "    return market_open <= now <= market_close\n",
    "\n",
    "# For debugging in Jupyter, you can disable the market check.\n",
    "# if not is_us_market_open():\n",
    "#     print(\"The US market is currently closed. Script execution halted.\")\n",
    "# else:\n",
    "load_dotenv()\n",
    "\n",
    "# Function to fetch S&P 500 tickers from Wikipedia\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    tickers = [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "    return tickers\n",
    "\n",
    "# Function to send a message via Telegram\n",
    "def send_telegram_message(message):\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "# Get the S&P 500 tickers and save to CSV\n",
    "sp500_tickers = get_sp500_tickers()\n",
    "os.makedirs('stockdata', exist_ok=True)\n",
    "pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "\n",
    "# Read tickers from CSV\n",
    "tickers_df = pd.read_csv('stockdata/sp500_tickers.csv')\n",
    "tickers = tickers_df['Ticker'].tolist()\n",
    "\n",
    "# Define the timeframe for downloading 60-minute data over the past 30 days.\n",
    "# We will later resample these bars to 2-hour bars.\n",
    "timeframes = {\n",
    "    '60m': timedelta(days=30),\n",
    "}\n",
    "recent_period = 2  # Look back the last 2 hours for new signals\n",
    "\n",
    "# --- New download approach using CachedLimiterSession and yf.Tickers ---\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "    limiter=Limiter(RequestRate(2, Duration.SECOND * 5)),  # max 2 requests per 5 seconds\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "\n",
    "# Create a Tickers object using all tickers with the custom session.\n",
    "# Note: yf.Tickers accepts a string of tickers separated by spaces.\n",
    "tickers_str = \" \".join(tickers)\n",
    "dat = yf.Tickers(tickers_str, session=session)\n",
    "\n",
    "data = {}\n",
    "screener_results = []  # list to store screener signal results\n",
    "\n",
    "for tf, delta in timeframes.items():\n",
    "    # Use period string based on the desired date range, e.g. \"30d\" for 30 days\n",
    "    period_str = f\"{delta.days}d\"\n",
    "    try:\n",
    "        his_data = dat.history(period=period_str, interval=tf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading bulk data for interval {tf}: {e}\")\n",
    "        continue\n",
    "\n",
    "    data[tf] = {}\n",
    "    # Get available tickers in the downloaded data from the MultiIndex level 'Ticker'\n",
    "    available_tickers = set(his_data.columns.get_level_values('Ticker'))\n",
    "    for ticker in tickers:\n",
    "        if ticker not in available_tickers:\n",
    "            print(f\"Ticker {ticker} not found in historical data, skipping.\")\n",
    "            continue\n",
    "        try:\n",
    "            # Extract data for a single ticker from the MultiIndex DataFrame and make a copy\n",
    "            df = his_data.xs(ticker, axis=1, level='Ticker').copy()\n",
    "            # Flatten the columns (Price types) if needed\n",
    "            df.columns = df.columns.get_level_values(0)\n",
    "            # Round OHLC values to two decimals using .loc to avoid SettingWithCopyWarning\n",
    "            for col in ['Open', 'High', 'Low', 'Close']:\n",
    "                if col in df.columns:\n",
    "                    df.loc[:, col] = df[col].round(2)\n",
    "\n",
    "            # Resample the 60m data to 2-hour bars\n",
    "            df_resampled = df.resample('2h').agg({\n",
    "                'Open': 'first',\n",
    "                'High': 'max',\n",
    "                'Low': 'min',\n",
    "                'Close': 'last',\n",
    "                'Volume': 'sum'\n",
    "            }).dropna()\n",
    "\n",
    "            # Calculate linear regression curves using pandas_ta\n",
    "            df_resampled['reg1'] = ta.linreg(df_resampled['Close'], length=25)\n",
    "            df_resampled['reg2'] = ta.linreg(df_resampled['Close'], length=50)\n",
    "\n",
    "            # Generate buy and sell signals\n",
    "            df_resampled['buy_signal'] = np.where(\n",
    "                (df_resampled['reg1'] > df_resampled['reg2']) & (df_resampled['reg1'].shift(1) <= df_resampled['reg2'].shift(1)),\n",
    "                1, 0\n",
    "            )\n",
    "            df_resampled['sell_signal'] = np.where(\n",
    "                (df_resampled['reg1'] < df_resampled['reg2']) & (df_resampled['reg1'].shift(1) >= df_resampled['reg2'].shift(1)),\n",
    "                1, 0\n",
    "            )\n",
    "\n",
    "            # Save each ticker's resampled data to a CSV file\n",
    "            csv_filename = f'stockdata/{ticker}_2h_data.csv'\n",
    "            df_resampled.to_csv(csv_filename)\n",
    "\n",
    "            # Filter for the recent period (last 2 hours)\n",
    "            if not df_resampled.empty:\n",
    "                recent_date_cutoff = df_resampled.index.max() - pd.Timedelta(hours=recent_period)\n",
    "                df_recent = df_resampled[df_resampled.index >= recent_date_cutoff]\n",
    "                df_filtered = df_recent[(df_recent['buy_signal'] == 1) | (df_recent['sell_signal'] == 1)]\n",
    "                if not df_filtered.empty:\n",
    "                    for index, row in df_filtered.iterrows():\n",
    "                        screener_results.append({\n",
    "                            'Ticker': ticker,\n",
    "                            'Date': index,\n",
    "                            'Buy Signal': row['buy_signal'],\n",
    "                            'Sell Signal': row['sell_signal']\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process data for ticker {ticker} on timeframe {tf}: {e}\")\n",
    "\n",
    "# Save the screener results to a CSV file\n",
    "screener_df = pd.DataFrame(screener_results)\n",
    "screener_df.to_csv('Regression_cross_screener_results_2h.csv', index=False)\n",
    "\n",
    "# Optionally, send results to Telegram if available\n",
    "if not screener_df.empty:\n",
    "    message = (\n",
    "        \"2hr Screener Results:\\n\"\n",
    "        \"Buy = linreg 25 crossover linreg 50\\n\"\n",
    "        \"Sell = linreg 25 cross below linreg 50\\n\"\n",
    "        f\"{screener_df.to_string(index=False)}\"\n",
    "    )\n",
    "    send_telegram_message(message)\n",
    "\n",
    "# Display a sample of the screener results\n",
    "print(\"2hr Screener Results:\\nBuy = linreg 25 crossover linreg 50\\nSell = linreg 25 cross below linreg 50\\n\")\n",
    "print(screener_df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2hr download new "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[**********************60%****                   ]  304 of 503 completedUnable to deserialize response: a bytes-like object is required, not 'NoneType'\n",
      "[*********************100%***********************]  503 of 503 completed\n",
      "\n",
      "3 Failed downloads:\n",
      "['MKTX']: InterfaceError('bad parameter or other API misuse')\n",
      "['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (period=30d)')\n",
      "['BRK.B']: YFPricesMissingError('possibly delisted; no price data found  (period=30d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2hr Screener Results:\n",
      "   Ticker                      Date  Buy Signal  Sell Signal\n",
      "53   TRMB 2025-02-21 20:00:00+00:00         0.0          1.0\n",
      "54    WFC 2025-02-21 18:00:00+00:00         0.0          1.0\n",
      "55    WST 2025-02-21 18:00:00+00:00         1.0          0.0\n",
      "56    WDC 2025-02-21 18:00:00+00:00         0.0          1.0\n",
      "57    ZTS 2025-02-21 20:00:00+00:00         1.0          0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pytz\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "############################\n",
    "# 1. Market Open Check\n",
    "############################\n",
    "def is_us_market_open():\n",
    "    \"\"\"\n",
    "    Checks if the current time is within US market hours (9:30 AM - 4:00 PM ET)\n",
    "    and not on weekends.\n",
    "    \"\"\"\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    now = datetime.now(eastern)\n",
    "    if now.weekday() in [5, 6]:  # Saturday and Sunday\n",
    "        return False\n",
    "    market_open = now.replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "    market_close = now.replace(hour=16, minute=0, second=0, microsecond=0)\n",
    "    return market_open <= now <= market_close\n",
    "\n",
    "############################\n",
    "# 2. Telegram Functions\n",
    "############################\n",
    "def send_telegram_message(message):\n",
    "    \"\"\"\n",
    "    Sends a given message to a Telegram chat.\n",
    "    \"\"\"\n",
    "    bot_token = os.getenv(\"TELEGRAM_BOT_TOKEN\")\n",
    "    chat_id = os.getenv(\"TELEGRAM_CHAT_ID\")\n",
    "    url = f\"https://api.telegram.org/bot{bot_token}/sendMessage\"\n",
    "    data = {\"chat_id\": chat_id, \"text\": message}\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "############################\n",
    "# 3. Utility Functions\n",
    "############################\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Fetches the S&P 500 tickers from Wikipedia.\n",
    "    \"\"\"\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'constituents'})\n",
    "    return [row.find('td').text.strip() for row in table.find_all('tr')[1:]]\n",
    "\n",
    "# Note: This download_data function is no longer used since we use a bulk download.\n",
    "# def download_data(ticker, timeframe, start_date, end_date):\n",
    "#     return yf.download(ticker, start=start_date, end=end_date, interval=timeframe)\n",
    "\n",
    "############################\n",
    "# 4. Bulk Download Setup using CachedLimiterSession and yf.Tickers\n",
    "############################\n",
    "from requests import Session\n",
    "from requests_cache import CacheMixin, SQLiteCache\n",
    "from requests_ratelimiter import LimiterMixin, MemoryQueueBucket\n",
    "from pyrate_limiter import Duration, RequestRate, Limiter\n",
    "\n",
    "class CachedLimiterSession(CacheMixin, LimiterMixin, Session):\n",
    "    pass\n",
    "\n",
    "session = CachedLimiterSession(\n",
    "    limiter=Limiter(RequestRate(2, Duration.SECOND * 5)),  # max 2 requests per 5 seconds\n",
    "    bucket_class=MemoryQueueBucket,\n",
    "    backend=SQLiteCache(\"yfinance.cache\"),\n",
    ")\n",
    "\n",
    "############################\n",
    "# 5. Main Screener\n",
    "############################\n",
    "def main():\n",
    "    # if not is_us_market_open():\n",
    "    #     print(\"The US market is currently closed. Script execution halted.\")\n",
    "    #     return\n",
    "    \n",
    "    # Create directory to store data\n",
    "    os.makedirs('stockdata', exist_ok=True)\n",
    "    \n",
    "    # Get S&P 500 tickers and save to CSV\n",
    "    sp500_tickers = get_sp500_tickers()\n",
    "    pd.DataFrame(sp500_tickers, columns=[\"Ticker\"]).to_csv('stockdata/sp500_tickers.csv', index=False)\n",
    "    \n",
    "    # Read tickers from CSV\n",
    "    tickers = pd.read_csv('stockdata/sp500_tickers.csv')['Ticker'].tolist()\n",
    "    \n",
    "    # Define the timeframe for bulk downloading 60m data over the past 30 days.\n",
    "    # We will later resample these bars to 2-hour bars.\n",
    "    timeframes = {\n",
    "        '60m': timedelta(days=30),\n",
    "    }\n",
    "    recent_period = 2  # Look back the last 2 hours for new signals\n",
    "    # Bulk download period string based on days\n",
    "    # (e.g., '30d' for 30 days)\n",
    "    \n",
    "    # Create a Tickers object with the custom CachedLimiterSession\n",
    "    tickers_str = \" \".join(tickers)\n",
    "    dat = yf.Tickers(tickers_str, session=session)\n",
    "    \n",
    "    data = {}\n",
    "    screener_results = []  # list to store screener signal results\n",
    "    \n",
    "    # Loop over defined timeframes (in this case, only '60m')\n",
    "    for tf, delta in timeframes.items():\n",
    "        period_str = f\"{delta.days}d\"\n",
    "        try:\n",
    "            his_data = dat.history(period=period_str, interval=tf)\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading bulk data for interval {tf}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        data[tf] = {}\n",
    "        # Extract available tickers from the MultiIndex level 'Ticker'\n",
    "        available_tickers = set(his_data.columns.get_level_values('Ticker'))\n",
    "        for ticker in tickers:\n",
    "            if ticker not in available_tickers:\n",
    "                print(f\"Ticker {ticker} not found in historical data, skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                # Extract data for a single ticker and make a copy\n",
    "                df = his_data.xs(ticker, axis=1, level='Ticker').copy()\n",
    "                # Flatten the columns (Price types) if needed\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "                # Round OHLC values to two decimals to avoid floating point issues\n",
    "                for col in ['Open', 'High', 'Low', 'Close']:\n",
    "                    if col in df.columns:\n",
    "                        df.loc[:, col] = df[col].round(2)\n",
    "                \n",
    "                # Resample the 60m data into 2-hour bars\n",
    "                df_resampled = df.resample('2h').agg({\n",
    "                    'Open': 'first',\n",
    "                    'High': 'max',\n",
    "                    'Low': 'min',\n",
    "                    'Close': 'last',\n",
    "                    'Volume': 'sum'\n",
    "                }).dropna()\n",
    "                \n",
    "                # Calculate linear regression curves using pandas_ta\n",
    "                df_resampled['reg1'] = ta.linreg(df_resampled['Close'], length=25)\n",
    "                df_resampled['reg2'] = ta.linreg(df_resampled['Close'], length=50)\n",
    "                \n",
    "                # Generate buy and sell signals\n",
    "                df_resampled['buy_signal'] = np.where(\n",
    "                    (df_resampled['reg1'] > df_resampled['reg2']) & (df_resampled['reg1'].shift(1) <= df_resampled['reg2'].shift(1)),\n",
    "                    1, 0\n",
    "                )\n",
    "                df_resampled['sell_signal'] = np.where(\n",
    "                    (df_resampled['reg1'] < df_resampled['reg2']) & (df_resampled['reg1'].shift(1) >= df_resampled['reg2'].shift(1)),\n",
    "                    1, 0\n",
    "                )\n",
    "                \n",
    "                # Save the resampled data to a CSV file for this ticker\n",
    "                csv_filename = f'stockdata/{ticker}_2h_data.csv'\n",
    "                df_resampled.to_csv(csv_filename)\n",
    "                \n",
    "                # Filter for the recent period (last 2 hours)\n",
    "                if not df_resampled.empty:\n",
    "                    recent_date_cutoff = df_resampled.index.max() - pd.Timedelta(hours=recent_period)\n",
    "                    df_recent = df_resampled[df_resampled.index >= recent_date_cutoff]\n",
    "                    df_filtered = df_recent[(df_recent['buy_signal'] == 1) | (df_recent['sell_signal'] == 1)]\n",
    "                    if not df_filtered.empty:\n",
    "                        for index, row in df_filtered.iterrows():\n",
    "                            screener_results.append({\n",
    "                                'Ticker': ticker,\n",
    "                                'Date': index,\n",
    "                                'Buy Signal': row['buy_signal'],\n",
    "                                'Sell Signal': row['sell_signal']\n",
    "                            })\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process data for ticker {ticker} on timeframe {tf}: {e}\")\n",
    "    \n",
    "    # Save the screener results to a CSV file\n",
    "    screener_df = pd.DataFrame(screener_results)\n",
    "    screener_df.to_csv('Regression_cross_screener_results_2h.csv', index=False)\n",
    "    \n",
    "    # If signals exist, print a sample and send them via Telegram\n",
    "    if not screener_df.empty:\n",
    "        print(f\"2hr Screener Results:\\n{str(screener_df.tail())}\")\n",
    "        message = (\n",
    "            \"2hr Screener Results:\\n\"\n",
    "            \"Buy = linreg(25) crosses above linreg(50)\\n\"\n",
    "            \"Sell = linreg(25) crosses below linreg(50)\\n\\n\"\n",
    "            + screener_df.to_string(index=False)\n",
    "        )\n",
    "        send_telegram_message(message)\n",
    "    else:\n",
    "        print(\"No buy/sell signals found in the last 2 hours.\")\n",
    "\n",
    "############################\n",
    "# 6. Entry Point\n",
    "############################\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
